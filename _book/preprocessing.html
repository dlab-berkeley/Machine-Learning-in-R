<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Preprocessing | Machine Learning in R</title>
  <meta name="description" content="D-Lab’s Machine Learning in R Workshop" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Preprocessing | Machine Learning in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="D-Lab’s Machine Learning in R Workshop" />
  <meta name="github-repo" content="dlab-berkeley/Machine-Learning-in-R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Preprocessing | Machine Learning in R" />
  
  <meta name="twitter:description" content="D-Lab’s Machine Learning in R Workshop" />
  



<meta name="date" content="2020-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="overview.html"/>
<link rel="next" href="ols-and-lasso.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#prereqs"><i class="fa fa-check"></i><b>1.1</b> Prereqs</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>2</b> Overview</a>
<ul>
<li class="chapter" data-level="2.1" data-path="overview.html"><a href="overview.html#package-installation"><i class="fa fa-check"></i><b>2.1</b> Package installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>3</b> Preprocessing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>3.1</b> Load packages</a></li>
<li class="chapter" data-level="3.2" data-path="preprocessing.html"><a href="preprocessing.html#load-the-data"><i class="fa fa-check"></i><b>3.2</b> Load the data</a></li>
<li class="chapter" data-level="3.3" data-path="preprocessing.html"><a href="preprocessing.html#read-background-information-and-variable-descriptions"><i class="fa fa-check"></i><b>3.3</b> Read background information and variable descriptions</a></li>
<li class="chapter" data-level="3.4" data-path="preprocessing.html"><a href="preprocessing.html#machine-learning-workflow"><i class="fa fa-check"></i><b>3.4</b> Machine learning workflow</a></li>
<li class="chapter" data-level="3.5" data-path="preprocessing.html"><a href="preprocessing.html#why-taking-a-tidyverse-approach-to-machine-learning"><i class="fa fa-check"></i><b>3.5</b> Why taking a tidyverse approach to machine learning?</a></li>
<li class="chapter" data-level="3.6" data-path="preprocessing.html"><a href="preprocessing.html#data-preprocessing"><i class="fa fa-check"></i><b>3.6</b> Data preprocessing</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="preprocessing.html"><a href="preprocessing.html#task-1-what-is-one-hot-encoding"><i class="fa fa-check"></i><b>3.6.1</b> Task 1: What is one-hot encoding?</a></li>
<li class="chapter" data-level="3.6.2" data-path="preprocessing.html"><a href="preprocessing.html#task-2-handling-missing-data"><i class="fa fa-check"></i><b>3.6.2</b> Task 2: Handling missing data</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="preprocessing.html"><a href="preprocessing.html#preprocessing-workflow"><i class="fa fa-check"></i><b>3.7</b> Preprocessing workflow</a></li>
<li class="chapter" data-level="3.8" data-path="preprocessing.html"><a href="preprocessing.html#regressioin-setup"><i class="fa fa-check"></i><b>3.8</b> Regressioin setup</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="preprocessing.html"><a href="preprocessing.html#outcome-variable"><i class="fa fa-check"></i><b>3.8.1</b> Outcome variable</a></li>
<li class="chapter" data-level="3.8.2" data-path="preprocessing.html"><a href="preprocessing.html#data-splitting-using-random-sampling"><i class="fa fa-check"></i><b>3.8.2</b> Data splitting using random sampling</a></li>
<li class="chapter" data-level="3.8.3" data-path="preprocessing.html"><a href="preprocessing.html#recipe"><i class="fa fa-check"></i><b>3.8.3</b> recipe</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="preprocessing.html"><a href="preprocessing.html#classification-setup"><i class="fa fa-check"></i><b>3.9</b> Classification setup</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="preprocessing.html"><a href="preprocessing.html#outcome-variable-1"><i class="fa fa-check"></i><b>3.9.1</b> Outcome variable</a></li>
<li class="chapter" data-level="3.9.2" data-path="preprocessing.html"><a href="preprocessing.html#data-splitting-using-stratified-random-sampling"><i class="fa fa-check"></i><b>3.9.2</b> Data splitting using stratified random sampling</a></li>
<li class="chapter" data-level="3.9.3" data-path="preprocessing.html"><a href="preprocessing.html#recipe-1"><i class="fa fa-check"></i><b>3.9.3</b> recipe</a></li>
<li class="chapter" data-level="3.9.4" data-path="preprocessing.html"><a href="preprocessing.html#save-our-preprocessed-data"><i class="fa fa-check"></i><b>3.9.4</b> Save our preprocessed data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html"><i class="fa fa-check"></i><b>4</b> OLS and lasso</a>
<ul>
<li class="chapter" data-level="4.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>4.1</b> Load packages</a></li>
<li class="chapter" data-level="4.2" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#load-data"><i class="fa fa-check"></i><b>4.2</b> Load data</a></li>
<li class="chapter" data-level="4.3" data-path="overview.html"><a href="overview.html#overview"><i class="fa fa-check"></i><b>4.3</b> Overview</a></li>
<li class="chapter" data-level="4.4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#fit-model"><i class="fa fa-check"></i><b>4.4</b> Fit model</a></li>
<li class="chapter" data-level="4.5" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#investigate-results"><i class="fa fa-check"></i><b>4.5</b> Investigate Results</a></li>
<li class="chapter" data-level="4.6" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#challenge-1"><i class="fa fa-check"></i><b>4.6</b> Challenge 1</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>5</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="5.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>5.1</b> Load packages</a></li>
<li class="chapter" data-level="5.2" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#load-data"><i class="fa fa-check"></i><b>5.2</b> Load data</a></li>
<li class="chapter" data-level="5.3" data-path="overview.html"><a href="overview.html#overview"><i class="fa fa-check"></i><b>5.3</b> Overview</a></li>
<li class="chapter" data-level="5.4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#fit-model"><i class="fa fa-check"></i><b>5.4</b> Fit Model</a></li>
<li class="chapter" data-level="5.5" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#investigate-results"><i class="fa fa-check"></i><b>5.5</b> Investigate Results</a></li>
<li class="chapter" data-level="5.6" data-path="decision-trees.html"><a href="decision-trees.html#challenge-2"><i class="fa fa-check"></i><b>5.6</b> Challenge 2</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>6</b> Random Forests</a>
<ul>
<li class="chapter" data-level="6.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>6.1</b> Load packages</a></li>
<li class="chapter" data-level="6.2" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#load-data"><i class="fa fa-check"></i><b>6.2</b> Load data</a></li>
<li class="chapter" data-level="6.3" data-path="overview.html"><a href="overview.html#overview"><i class="fa fa-check"></i><b>6.3</b> Overview</a></li>
<li class="chapter" data-level="6.4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#fit-model"><i class="fa fa-check"></i><b>6.4</b> Fit model</a></li>
<li class="chapter" data-level="6.5" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#investigate-results"><i class="fa fa-check"></i><b>6.5</b> Investigate Results</a></li>
<li class="chapter" data-level="6.6" data-path="random-forests.html"><a href="random-forests.html#challenge-3"><i class="fa fa-check"></i><b>6.6</b> Challenge 3</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="xgboost.html"><a href="xgboost.html"><i class="fa fa-check"></i><b>7</b> XGBoost</a>
<ul>
<li class="chapter" data-level="7.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>7.1</b> Load packages</a></li>
<li class="chapter" data-level="7.2" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#load-data"><i class="fa fa-check"></i><b>7.2</b> Load data</a></li>
<li class="chapter" data-level="7.3" data-path="overview.html"><a href="overview.html#overview"><i class="fa fa-check"></i><b>7.3</b> Overview</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="xgboost.html"><a href="xgboost.html#define-cv_control"><i class="fa fa-check"></i><b>7.3.1</b> Define <code>cv_control</code></a></li>
<li class="chapter" data-level="7.3.2" data-path="xgboost.html"><a href="xgboost.html#define-xgb_grid"><i class="fa fa-check"></i><b>7.3.2</b> Define <code>xgb_grid</code></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#fit-model"><i class="fa fa-check"></i><b>7.4</b> Fit model</a></li>
<li class="chapter" data-level="7.5" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#investigate-results"><i class="fa fa-check"></i><b>7.5</b> Investigate Results</a></li>
<li class="chapter" data-level="7.6" data-path="xgboost.html"><a href="xgboost.html#challenge-4"><i class="fa fa-check"></i><b>7.6</b> Challenge 4</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ensembles.html"><a href="ensembles.html"><i class="fa fa-check"></i><b>8</b> Ensembles</a>
<ul>
<li class="chapter" data-level="8.1" data-path="preprocessing.html"><a href="preprocessing.html#load-packages"><i class="fa fa-check"></i><b>8.1</b> Load packages</a></li>
<li class="chapter" data-level="8.2" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#load-data"><i class="fa fa-check"></i><b>8.2</b> Load data</a></li>
<li class="chapter" data-level="8.3" data-path="overview.html"><a href="overview.html#overview"><i class="fa fa-check"></i><b>8.3</b> Overview</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ensembles.html"><a href="ensembles.html#choose-algorithms"><i class="fa fa-check"></i><b>8.3.1</b> Choose algorithms</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ols-and-lasso.html"><a href="ols-and-lasso.html#fit-model"><i class="fa fa-check"></i><b>8.4</b> Fit Model</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ensembles.html"><a href="ensembles.html#risk"><i class="fa fa-check"></i><b>8.4.1</b> Risk</a></li>
<li class="chapter" data-level="8.4.2" data-path="ensembles.html"><a href="ensembles.html#plot-the-risk"><i class="fa fa-check"></i><b>8.4.2</b> Plot the risk</a></li>
<li class="chapter" data-level="8.4.3" data-path="ensembles.html"><a href="ensembles.html#compute-auc-for-all-estimators"><i class="fa fa-check"></i><b>8.4.3</b> Compute AUC for all estimators</a></li>
<li class="chapter" data-level="8.4.4" data-path="ensembles.html"><a href="ensembles.html#plot-the-roc-curve-for-the-best-estimator"><i class="fa fa-check"></i><b>8.4.4</b> Plot the ROC curve for the best estimator</a></li>
<li class="chapter" data-level="8.4.5" data-path="ensembles.html"><a href="ensembles.html#review-weight-distribution-for-the-superlearner"><i class="fa fa-check"></i><b>8.4.5</b> Review weight distribution for the SuperLearner</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ensembles.html"><a href="ensembles.html#challenge-5"><i class="fa fa-check"></i><b>8.5</b> Challenge 5</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>9</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#unsupervised-approaches"><i class="fa fa-check"></i><b>9.1</b> Unsupervised approaches</a></li>
<li class="chapter" data-level="9.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#reclass-variables"><i class="fa fa-check"></i><b>9.2</b> Reclass variables</a></li>
<li class="chapter" data-level="9.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#scale-numeric-variables"><i class="fa fa-check"></i><b>9.3</b> Scale numeric variables</a></li>
<li class="chapter" data-level="9.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#factorize-categorical-variables"><i class="fa fa-check"></i><b>9.4</b> Factorize categorical variables</a></li>
<li class="chapter" data-level="9.5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#screeplot"><i class="fa fa-check"></i><b>9.5</b> Screeplot</a></li>
<li class="chapter" data-level="9.6" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#ggplot-coordinates"><i class="fa fa-check"></i><b>9.6</b> ggplot coordinates</a></li>
<li class="chapter" data-level="9.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#view-factor-loadings"><i class="fa fa-check"></i><b>9.7</b> View factor loadings</a></li>
<li class="chapter" data-level="9.8" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#generate-predicted-values-of-pcs-for-test-dataset"><i class="fa fa-check"></i><b>9.8</b> Generate predicted values of PCs for test dataset</a></li>
<li class="chapter" data-level="9.9" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#define-plotting-parameters"><i class="fa fa-check"></i><b>9.9</b> Define plotting parameters</a></li>
<li class="chapter" data-level="9.10" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#store-the-scores-inside-of-dataframes"><i class="fa fa-check"></i><b>9.10</b> Store the scores inside of dataframes</a></li>
<li class="chapter" data-level="9.11" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#save-ml_num-for-use-in-09-hclust.rmd"><i class="fa fa-check"></i><b>9.11</b> Save <code>ml_num</code> for use in 09-hclust.Rmd</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html"><i class="fa fa-check"></i><b>10</b> Hierarchical Agglomerative Clustering</a>
<ul>
<li class="chapter" data-level="10.1" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#compare-different-dissimilarity-measures"><i class="fa fa-check"></i><b>10.1</b> Compare different dissimilarity measures</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#wards-method-minimum-variance-between-clusters"><i class="fa fa-check"></i><b>10.1.1</b> Ward’s method: minimum variance between clusters</a></li>
<li class="chapter" data-level="10.1.2" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#complete-linkage-largest-intercluster-difference"><i class="fa fa-check"></i><b>10.1.2</b> Complete linkage: largest intercluster difference</a></li>
<li class="chapter" data-level="10.1.3" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#single-linkage-smallest-intercluster-difference"><i class="fa fa-check"></i><b>10.1.3</b> Single linkage: smallest intercluster difference</a></li>
<li class="chapter" data-level="10.1.4" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#average-linkage-mean-intercluster-difference"><i class="fa fa-check"></i><b>10.1.4</b> Average linkage: mean intercluster difference</a></li>
<li class="chapter" data-level="10.1.5" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#view-summaries"><i class="fa fa-check"></i><b>10.1.5</b> View summaries</a></li>
<li class="chapter" data-level="10.1.6" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#plot-euclidean-distance-linkages"><i class="fa fa-check"></i><b>10.1.6</b> Plot Euclidean distance linkages</a></li>
<li class="chapter" data-level="10.1.7" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#view-standard-error-plots"><i class="fa fa-check"></i><b>10.1.7</b> View standard error plots:</a></li>
<li class="chapter" data-level="10.1.8" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#return-best-performing-model"><i class="fa fa-check"></i><b>10.1.8</b> Return best performing model</a></li>
<li class="chapter" data-level="10.1.9" data-path="hierarchical-agglomerative-clustering.html"><a href="hierarchical-agglomerative-clustering.html#cross-validated-mclust"><i class="fa fa-check"></i><b>10.1.9</b> Cross-validated mclust</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="preprocessing" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Preprocessing</h1>
<div id="load-packages" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Load packages</h2>
<p>Explicitly load the packages that we need for this analysis.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="preprocessing.html#cb1-1"></a><span class="kw">library</span>(rio) <span class="co"># painless data import and export</span></span>
<span id="cb1-2"><a href="preprocessing.html#cb1-2"></a><span class="kw">library</span>(tidyverse) <span class="co"># tidyverse packages </span></span></code></pre></div>
<pre><code>## ── Attaching packages ────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.5.0</code></pre>
<pre><code>## ── Conflicts ───────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="preprocessing.html#cb5-1"></a><span class="kw">library</span>(tidymodels) <span class="co"># tidymodels framework </span></span></code></pre></div>
<pre><code>## ── Attaching packages ───────────────────── tidymodels 0.1.1 ──</code></pre>
<pre><code>## ✓ broom     0.7.0      ✓ recipes   0.1.13
## ✓ dials     0.0.9      ✓ rsample   0.0.7 
## ✓ infer     0.5.3      ✓ tune      0.1.1 
## ✓ modeldata 0.0.2      ✓ workflows 0.2.0 
## ✓ parsnip   0.1.3      ✓ yardstick 0.0.7</code></pre>
<pre><code>## ── Conflicts ──────────────────────── tidymodels_conflicts() ──
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="preprocessing.html#cb9-1"></a><span class="kw">library</span>(here) <span class="co"># reproducible way to find files </span></span></code></pre></div>
<pre><code>## here() starts at /home/jae/Machine-Learning-in-R</code></pre>
</div>
<div id="load-the-data" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Load the data</h2>
<p>Load the heart disease dataset.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="preprocessing.html#cb11-1"></a><span class="co"># Load the heart disease dataset using import() from the rio package.</span></span>
<span id="cb11-2"><a href="preprocessing.html#cb11-2"></a>data_original &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="kw">here</span>(<span class="st">&quot;data-raw&quot;</span>, <span class="st">&quot;heart.csv&quot;</span>))</span>
<span id="cb11-3"><a href="preprocessing.html#cb11-3"></a></span>
<span id="cb11-4"><a href="preprocessing.html#cb11-4"></a><span class="co"># Preserve the original copy</span></span>
<span id="cb11-5"><a href="preprocessing.html#cb11-5"></a>data &lt;-<span class="st"> </span>data_original</span>
<span id="cb11-6"><a href="preprocessing.html#cb11-6"></a></span>
<span id="cb11-7"><a href="preprocessing.html#cb11-7"></a><span class="co"># Inspect </span></span>
<span id="cb11-8"><a href="preprocessing.html#cb11-8"></a><span class="kw">glimpse</span>(data)</span></code></pre></div>
<pre><code>## Rows: 303
## Columns: 14
## $ age      &lt;int&gt; 63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, …
## $ sex      &lt;int&gt; 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, …
## $ cp       &lt;int&gt; 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3, 2, 2, 3, 0, 3, …
## $ trestbps &lt;int&gt; 145, 130, 130, 120, 120, 140, 140, 120, 172, 150, 140, 130, …
## $ chol     &lt;int&gt; 233, 250, 204, 236, 354, 192, 294, 263, 199, 168, 239, 275, …
## $ fbs      &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …
## $ restecg  &lt;int&gt; 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …
## $ thalach  &lt;int&gt; 150, 187, 172, 178, 163, 148, 153, 173, 162, 174, 160, 139, …
## $ exang    &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …
## $ oldpeak  &lt;dbl&gt; 2.3, 3.5, 1.4, 0.8, 0.6, 0.4, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, …
## $ slope    &lt;int&gt; 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, …
## $ ca       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, …
## $ thal     &lt;int&gt; 1, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …
## $ target   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="preprocessing.html#cb13-1"></a><span class="kw">class</span>(data)</span></code></pre></div>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
</div>
<div id="read-background-information-and-variable-descriptions" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Read background information and variable descriptions</h2>
<p><a href="https://archive.ics.uci.edu/ml/datasets/heart+Disease" class="uri">https://archive.ics.uci.edu/ml/datasets/heart+Disease</a></p>
<div class="figure">
<img src="https://archive.ics.uci.edu/ml/assets/MLimages/Large45.jpg" alt="" />
<p class="caption">Heart Diseases dataset availalbe at the UCI Machine Learning Repository</p>
</div>
</div>
<div id="machine-learning-workflow" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Machine learning workflow</h2>
<p>Before diving into the specific problem (i.e., preprocessing), let’s take a step back and think about the big picture.</p>
<p><img src="https://www.tmwr.org/premade/modeling-process.svg" alt="A schematic for the typical modeling process (from Tidy Modeling with R)" />
- Preeprocessing happens between the EDA and the initial feature engineering.</p>
</div>
<div id="why-taking-a-tidyverse-approach-to-machine-learning" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Why taking a tidyverse approach to machine learning?</h2>
<ul>
<li>Readable code (e.g., <code>dplyr</code> is quite intuitive even for beginning R users.)</li>
<li>Reusable data structures (e.g., <code>broom</code> package helps to visualize model outputs, such as p-value, using <code>ggplot2</code>)</li>
<li>Extendable code (e.g., you can easily build a machine learning pipeline by using the pipe operator (<code>%&gt;%</code>) and the <code>purrr</code> package)</li>
</ul>
</div>
<div id="data-preprocessing" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Data preprocessing</h2>
<p>Data peprocessing is an integral first step in machine learning workflows. Because different algorithms sometimes require the moving parts to be coded in slightly different ways, always make sure you research the algorithm you want to implement so that you properly setup your <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> variables and split your data appropriately.</p>
<blockquote>
<p>NOTE: also, use the <code>save</code> function to save your variables of interest. In the remaining walkthroughs, we will use the <code>load</code> function to load the relevant variables.</p>
</blockquote>
<p>The list of the preprocessing steps draws on the vignette of the <a href="https://www.tidymodels.org/find/parsnip/"><code>parsnip</code></a> package.</p>
<ul>
<li>dummy: Also called one-hot encoding</li>
<li>zero variance: Removing columns (or features) with a single unique value<br />
</li>
<li>impute: Imputing missing values</li>
<li>decorrelate: Mitigating correlated predictors (e.g., principal component analysis)</li>
<li>normalize: Centering and/or scaling predictors (e.g., log scaling)</li>
<li>transform: Making predictors symmetric</li>
</ul>
<p>In this workshop, we focus on two preprocessing tasks.</p>
<div id="task-1-what-is-one-hot-encoding" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Task 1: What is one-hot encoding?</h3>
<p>One additional preprocessing aspect to consider: datasets that contain factor (categorical) features should typically be expanded out into numeric indicators (this is often referred to as <a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f">one-hot encoding</a>. You can do this manually with the <code>model.matrix</code> R function. This makes it easier to code a variety of algorithms to a dataset as many algorithms handle factors poorly (decision trees being the main exception). Doing this manually is always good practice. In general however, functions like <code>lm</code> will do this for you automatically.</p>
<ul>
<li>Since the “ca”, “cp”, “slope”, and “thal” features are currently integer type, convert them to factors. The other relevant variables are either continuous or are already indicators (just 1’s and 0’s).</li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="preprocessing.html#cb15-1"></a><span class="co"># Turn selected numeric variables into factor variables </span></span>
<span id="cb15-2"><a href="preprocessing.html#cb15-2"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span></span>
<span id="cb15-3"><a href="preprocessing.html#cb15-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>), as.factor)) </span></code></pre></div>
</div>
<div id="task-2-handling-missing-data" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Task 2: Handling missing data</h3>
<p>Missing values need to be handled somehow. Listwise deletion (deleting any row with at least one missing value) is common but this method throws out a lot of useful information. Many advocate for mean imputation, but arithmetic means are sensitive to outliers. Still, others advocate for Chained Equation/Bayesian/Expectation Maximization imputation (e.g., the <a href="https://www.jstatsoft.org/article/view/v045i03/v45i03.pdf">mice</a> and <a href="https://gking.harvard.edu/amelia">Amelia II</a> R packages). K-nearest neighbor imputation can also be useful but median imputation is demonstrated below.</p>
<p>However, you will want to learn about <a href="https://stanford.edu/~boyd/papers/pdf/glrm.pdf">Generalized Low Rank Models</a> for missing data imputation in your research. See the <code>impute_missing_values</code> function from the ck37r package to learn more - you might need to install an h2o dependency.</p>
<p>First, count the number of missing values across variables in our dataset.</p>
<ul>
<li>Using base R</li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="preprocessing.html#cb16-1"></a><span class="co"># Using base R; The output is a numeric vector.  </span></span>
<span id="cb16-2"><a href="preprocessing.html#cb16-2"></a><span class="kw">colSums</span>(<span class="kw">is.na</span>(data))</span></code></pre></div>
<pre><code>##      age      sex       cp trestbps     chol      fbs  restecg  thalach 
##        0        0        0        0        0        0        0        0 
##    exang  oldpeak    slope       ca     thal   target 
##        0        0        0        0        0        0</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="preprocessing.html#cb18-1"></a><span class="kw">class</span>(<span class="kw">colSums</span>(<span class="kw">is.na</span>(data)))</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<ul>
<li>Using tidyverse</li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="preprocessing.html#cb20-1"></a><span class="co"># Using tidyverse; The output is a dataframe.</span></span>
<span id="cb20-2"><a href="preprocessing.html#cb20-2"></a><span class="co"># Option 1 and Option 2 produce same outputs. </span></span>
<span id="cb20-3"><a href="preprocessing.html#cb20-3"></a></span>
<span id="cb20-4"><a href="preprocessing.html#cb20-4"></a><span class="kw">map_df</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()) <span class="co"># Option 1</span></span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;
## 1     0     0     0        0     0     0       0       0     0       0     0
## # … with 3 more variables: ca &lt;int&gt;, thal &lt;int&gt;, target &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="preprocessing.html#cb22-1"></a><span class="kw">map_df</span>(data, </span>
<span id="cb22-2"><a href="preprocessing.html#cb22-2"></a>       <span class="cf">function</span>(x){<span class="kw">is.na</span>(x) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()}) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Option 2 </span></span>
<span id="cb22-3"><a href="preprocessing.html#cb22-3"></a><span class="st">  </span><span class="kw">as_tibble</span>()</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;
## 1     0     0     0        0     0     0       0       0     0       0     0
## # … with 3 more variables: ca &lt;int&gt;, thal &lt;int&gt;, target &lt;int&gt;</code></pre>
<p>We have no missing values, so let’s introduce a few to the “oldpeak” feature for this example to see how it works:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="preprocessing.html#cb24-1"></a><span class="co"># Add five missing values added to oldpeak in row numbers 50, 100, 150, 200, 250</span></span>
<span id="cb24-2"><a href="preprocessing.html#cb24-2"></a></span>
<span id="cb24-3"><a href="preprocessing.html#cb24-3"></a>data<span class="op">$</span>oldpeak[<span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>)] &lt;-<span class="st"> </span><span class="ot">NA</span></span></code></pre></div>
<p>There are now 5 missing values in the “oldpeak” feature.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="preprocessing.html#cb25-1"></a><span class="co"># Check the number of missing values </span></span>
<span id="cb25-2"><a href="preprocessing.html#cb25-2"></a>data <span class="op">%&gt;%</span></span>
<span id="cb25-3"><a href="preprocessing.html#cb25-3"></a><span class="st">  </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;
## 1     0     0     0        0     0     0       0       0     0       5     0
## # … with 3 more variables: ca &lt;int&gt;, thal &lt;int&gt;, target &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="preprocessing.html#cb27-1"></a><span class="co"># Check the rate of missing values</span></span>
<span id="cb27-2"><a href="preprocessing.html#cb27-2"></a>data <span class="op">%&gt;%</span></span>
<span id="cb27-3"><a href="preprocessing.html#cb27-3"></a><span class="st">  </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">is.na</span>(.) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1     0     0     0        0     0     0       0       0     0  0.0165     0
## # … with 3 more variables: ca &lt;dbl&gt;, thal &lt;dbl&gt;, target &lt;dbl&gt;</code></pre>
</div>
</div>
<div id="preprocessing-workflow" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Preprocessing workflow</h2>
<div class="figure">
<img src="https://education.rstudio.com/blog/2020/02/conf20-intro-ml/recipes.png" alt="" />
<p class="caption">Art by Allison Horst</p>
</div>
<ul>
<li><p>Step 1: <code>recipe()</code> defines target and predictor variables (ingredients).</p></li>
<li><p>Step 2: <code>step_*()</code> defines preprocessing steps to be taken (recipe).</p></li>
<li><p>Step 3: <code>prep()</code> prepares a dataset to base each step on.</p></li>
<li><p>Step 4: <code>bake()</code> applies the pre-processing steps to your datasets.</p></li>
</ul>
<p><strong>Useful references</strong></p>
<ul>
<li>Alison Hill, <a href="https://education.rstudio.com/blog/2020/02/conf20-intro-ml/">“Introduction Machine Learning with the Tidyverse”</a></li>
<li>Rebecca Barter, <a href="http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/">“Using the recipes package for easy pre-processing”</a></li>
</ul>
</div>
<div id="regressioin-setup" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> Regressioin setup</h2>
<p>Splitting data into training and test subsets is a fundamental step in machine learning. Usually, the marjority portion of the original dataset is partitioned to the training set, where the algorithms learn the relationships between the <span class="math inline">\(x\)</span> feature predictors and the <span class="math inline">\(y\)</span> outcome variable. Then, these models are given new data (the test set) to see how well they perform on data they have not yet seen.</p>
<p>Since <strong>age</strong> is a <strong>continuous variable</strong> and will be <strong>the outcome</strong> for the OLS and lasso regressions, we will not perform a stratified random split like we will for the classification tasks (see below). Instead, <a href="https://stackoverflow.com/questions/17200114/how-to-split-data-into-training-testing-sets-using-sample-function">let’s randomly assign</a> 70% of the <code>age</code> values to the training set and the remaining 30% to the test set.</p>
<div id="outcome-variable" class="section level3" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> Outcome variable</h3>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="preprocessing.html#cb29-1"></a><span class="co"># Continuous variable </span></span>
<span id="cb29-2"><a href="preprocessing.html#cb29-2"></a>data<span class="op">$</span>age <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unique</span>()</span></code></pre></div>
<pre><code>##  [1] 63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 69 59 42 61 40 71 51 65 53 46
## [26] 45 39 47 62 34 35 29 55 60 67 68 74 76 70 38 77</code></pre>
</div>
<div id="data-splitting-using-random-sampling" class="section level3" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Data splitting using random sampling</h3>
<p>Take the simple approach to data splitting and divide our data into training and test sets; 70% of the data will be assigned to the training set and the remaining 30% will be assigned to the holdout, or test, set.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="preprocessing.html#cb31-1"></a><span class="co"># for reproducibility </span></span>
<span id="cb31-2"><a href="preprocessing.html#cb31-2"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) </span>
<span id="cb31-3"><a href="preprocessing.html#cb31-3"></a></span>
<span id="cb31-4"><a href="preprocessing.html#cb31-4"></a><span class="co"># split </span></span>
<span id="cb31-5"><a href="preprocessing.html#cb31-5"></a>split_reg &lt;-<span class="st"> </span><span class="kw">initial_split</span>(data, <span class="dt">prop =</span> <span class="fl">0.7</span>)</span>
<span id="cb31-6"><a href="preprocessing.html#cb31-6"></a></span>
<span id="cb31-7"><a href="preprocessing.html#cb31-7"></a><span class="co"># training set </span></span>
<span id="cb31-8"><a href="preprocessing.html#cb31-8"></a>raw_train_x_reg &lt;-<span class="st"> </span><span class="kw">training</span>(split_reg)</span>
<span id="cb31-9"><a href="preprocessing.html#cb31-9"></a></span>
<span id="cb31-10"><a href="preprocessing.html#cb31-10"></a><span class="co"># test set </span></span>
<span id="cb31-11"><a href="preprocessing.html#cb31-11"></a>raw_test_x_reg &lt;-<span class="st"> </span><span class="kw">testing</span>(split_reg)</span></code></pre></div>
</div>
<div id="recipe" class="section level3" number="3.8.3">
<h3><span class="header-section-number">3.8.3</span> recipe</h3>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="preprocessing.html#cb32-1"></a><span class="co">## Regression recipe </span></span>
<span id="cb32-2"><a href="preprocessing.html#cb32-2"></a>recipe_reg &lt;-<span class="st"> </span>raw_train_x_reg <span class="op">%&gt;%</span></span>
<span id="cb32-3"><a href="preprocessing.html#cb32-3"></a><span class="st">  </span><span class="co"># Define the outcome variable </span></span>
<span id="cb32-4"><a href="preprocessing.html#cb32-4"></a><span class="st">  </span><span class="kw">recipe</span>(age <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span></span>
<span id="cb32-5"><a href="preprocessing.html#cb32-5"></a><span class="st">  </span><span class="co"># Median impute oldpeak column </span></span>
<span id="cb32-6"><a href="preprocessing.html#cb32-6"></a><span class="st">  </span><span class="kw">step_medianimpute</span>(oldpeak) <span class="op">%&gt;%</span></span>
<span id="cb32-7"><a href="preprocessing.html#cb32-7"></a><span class="st">  </span><span class="co"># Expand &quot;sex&quot;, &quot;ca&quot;, &quot;cp&quot;, &quot;slope&quot;, and &quot;thal&quot; features out into dummy variables (indicators). </span></span>
<span id="cb32-8"><a href="preprocessing.html#cb32-8"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb32-9"><a href="preprocessing.html#cb32-9"></a><span class="st">  </span><span class="co"># Prepare a dataset to base each step on</span></span>
<span id="cb32-10"><a href="preprocessing.html#cb32-10"></a><span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> raw_train_x_reg) </span>
<span id="cb32-11"><a href="preprocessing.html#cb32-11"></a></span>
<span id="cb32-12"><a href="preprocessing.html#cb32-12"></a><span class="co"># x features </span></span>
<span id="cb32-13"><a href="preprocessing.html#cb32-13"></a>train_x_reg &lt;-<span class="st"> </span><span class="kw">bake</span>(recipe_reg, raw_train_x_reg)</span>
<span id="cb32-14"><a href="preprocessing.html#cb32-14"></a>test_x_reg &lt;-<span class="st"> </span><span class="kw">bake</span>(recipe_reg, raw_test_x_reg)</span>
<span id="cb32-15"><a href="preprocessing.html#cb32-15"></a></span>
<span id="cb32-16"><a href="preprocessing.html#cb32-16"></a><span class="co"># y variables </span></span>
<span id="cb32-17"><a href="preprocessing.html#cb32-17"></a>train_y_reg &lt;-<span class="st"> </span>train_x_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(age)</span>
<span id="cb32-18"><a href="preprocessing.html#cb32-18"></a>test_y_reg &lt;-<span class="st"> </span>test_x_reg <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(age)</span></code></pre></div>
<ul>
<li>Note that other imputation methods are also available. Fancier methods tend to take longer time than simpler ones such as mean, median, or mode imputation.</li>
</ul>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="preprocessing.html#cb33-1"></a><span class="kw">grep</span>(<span class="st">&quot;impute&quot;</span>, <span class="kw">ls</span>(<span class="st">&quot;package:recipes&quot;</span>), <span class="dt">value =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  [1] &quot;step_bagimpute&quot;          &quot;step_knnimpute&quot;         
##  [3] &quot;step_lowerimpute&quot;        &quot;step_meanimpute&quot;        
##  [5] &quot;step_medianimpute&quot;       &quot;step_modeimpute&quot;        
##  [7] &quot;step_rollimpute&quot;         &quot;tunable.step_bagimpute&quot; 
##  [9] &quot;tunable.step_knnimpute&quot;  &quot;tunable.step_meanimpute&quot;
## [11] &quot;tunable.step_rollimpute&quot;</code></pre>
<ul>
<li><p>You can also create your own <code>step_</code> functions. For more information, see <a href="https://www.tidymodels.org/learn/develop/recipes/">tidymodels.org</a>.</p></li>
<li><p>Now that the data have been imputed and properly converted, we can assign the regression outcome variable (<code>age</code>) to its own vector for the lasso <strong>REGRESSION task</strong>. Remember that lasso can also perform classification as well.</p></li>
</ul>
</div>
</div>
<div id="classification-setup" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Classification setup</h2>
<p>Assign the outcome variable to its own vector for the decision tree, random forest, gradient boosted tree, and SuperLearner ensemble <strong>CLASSIFICATION tasks</strong>. However, keep in mind that these algorithms can also perform regression!</p>
<p>This time however, <strong>“target”</strong> will by our y <strong>outcome variable</strong> (1 = person has heart disease, 0 = person does not have heart disease) - the others will be our x features.</p>
<div id="outcome-variable-1" class="section level3" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Outcome variable</h3>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="preprocessing.html#cb35-1"></a><span class="co">## Categorical variable </span></span>
<span id="cb35-2"><a href="preprocessing.html#cb35-2"></a>data<span class="op">$</span>target <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unique</span>()</span></code></pre></div>
<pre><code>## [1] 1 0</code></pre>
</div>
<div id="data-splitting-using-stratified-random-sampling" class="section level3" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Data splitting using stratified random sampling</h3>
<p>For classification, we then use <a href="https://stats.stackexchange.com/questions/250273/benefits-of-stratified-vs-random-sampling-for-generating-training-data-in-classi">stratified random sampling</a> to divide our data into training and test sets; 70% of the data will be assigned to the training set and the remaining 30% will be assigned to the holdout, or test, set.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="preprocessing.html#cb37-1"></a><span class="co"># split </span></span>
<span id="cb37-2"><a href="preprocessing.html#cb37-2"></a>split_class &lt;-<span class="st"> </span><span class="kw">initial_split</span>(data, <span class="dt">prop =</span> <span class="fl">0.7</span>, <span class="dt">strata =</span> target)</span>
<span id="cb37-3"><a href="preprocessing.html#cb37-3"></a></span>
<span id="cb37-4"><a href="preprocessing.html#cb37-4"></a><span class="co"># training set </span></span>
<span id="cb37-5"><a href="preprocessing.html#cb37-5"></a>raw_train_x_class &lt;-<span class="st"> </span><span class="kw">training</span>(split_class)</span>
<span id="cb37-6"><a href="preprocessing.html#cb37-6"></a></span>
<span id="cb37-7"><a href="preprocessing.html#cb37-7"></a><span class="co"># testing set </span></span>
<span id="cb37-8"><a href="preprocessing.html#cb37-8"></a>raw_test_x_class &lt;-<span class="st"> </span><span class="kw">testing</span>(split_class)</span></code></pre></div>
</div>
<div id="recipe-1" class="section level3" number="3.9.3">
<h3><span class="header-section-number">3.9.3</span> recipe</h3>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="preprocessing.html#cb38-1"></a><span class="co">## Classification recipe </span></span>
<span id="cb38-2"><a href="preprocessing.html#cb38-2"></a>recipe_class &lt;-<span class="st"> </span>raw_train_x_class <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb38-3"><a href="preprocessing.html#cb38-3"></a><span class="st">  </span><span class="co"># Define the outcome variable </span></span>
<span id="cb38-4"><a href="preprocessing.html#cb38-4"></a><span class="st">  </span><span class="kw">recipe</span>(target <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span></span>
<span id="cb38-5"><a href="preprocessing.html#cb38-5"></a><span class="st">  </span><span class="co"># Median impute oldpeak column </span></span>
<span id="cb38-6"><a href="preprocessing.html#cb38-6"></a><span class="st">  </span><span class="kw">step_medianimpute</span>(oldpeak) <span class="op">%&gt;%</span></span>
<span id="cb38-7"><a href="preprocessing.html#cb38-7"></a><span class="st">  </span><span class="co"># Expand &quot;sex&quot;, &quot;ca&quot;, &quot;cp&quot;, &quot;slope&quot;, and &quot;thal&quot; features out into dummy variables (indicators). </span></span>
<span id="cb38-8"><a href="preprocessing.html#cb38-8"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ca&quot;</span>, <span class="st">&quot;cp&quot;</span>, <span class="st">&quot;slope&quot;</span>, <span class="st">&quot;thal&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb38-9"><a href="preprocessing.html#cb38-9"></a><span class="st">  </span><span class="co"># Prepare a dataset to base each step on</span></span>
<span id="cb38-10"><a href="preprocessing.html#cb38-10"></a><span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> raw_train_x_class) </span>
<span id="cb38-11"><a href="preprocessing.html#cb38-11"></a></span>
<span id="cb38-12"><a href="preprocessing.html#cb38-12"></a><span class="co"># x features </span></span>
<span id="cb38-13"><a href="preprocessing.html#cb38-13"></a>train_x_class &lt;-<span class="st"> </span><span class="kw">bake</span>(recipe_class, raw_train_x_class)</span>
<span id="cb38-14"><a href="preprocessing.html#cb38-14"></a>test_x_class &lt;-<span class="st"> </span><span class="kw">bake</span>(recipe_class, raw_test_x_class)</span>
<span id="cb38-15"><a href="preprocessing.html#cb38-15"></a></span>
<span id="cb38-16"><a href="preprocessing.html#cb38-16"></a><span class="co"># y variables </span></span>
<span id="cb38-17"><a href="preprocessing.html#cb38-17"></a>train_y_class &lt;-<span class="st"> </span>train_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(target)</span>
<span id="cb38-18"><a href="preprocessing.html#cb38-18"></a>test_y_class &lt;-<span class="st"> </span>test_x_class <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(target)</span></code></pre></div>
</div>
<div id="save-our-preprocessed-data" class="section level3" number="3.9.4">
<h3><span class="header-section-number">3.9.4</span> Save our preprocessed data</h3>
<p>We save our preprocessed data into an RData file so that we can easily load it the later files.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="preprocessing.html#cb39-1"></a><span class="kw">save</span>(data, data_original, </span>
<span id="cb39-2"><a href="preprocessing.html#cb39-2"></a>     train_x_reg, train_y_reg, test_x_reg, test_y_reg,</span>
<span id="cb39-3"><a href="preprocessing.html#cb39-3"></a>     train_x_class, train_y_class, test_x_class, test_y_class,</span>
<span id="cb39-4"><a href="preprocessing.html#cb39-4"></a>     <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;preprocessed.RData&quot;</span>))</span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ols-and-lasso.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dlab-berkeley/Machine-Learning-in-R/edit/master/02-preprocessing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["machine-learning-in-r.pdf", "machine-learning-in-r.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
